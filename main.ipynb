{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文字預測股票漲跌專案\n",
    "\n",
    "***根據網路上各類新聞文章預測某一公司股價的漲跌***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "台大經研所 羅偉駿\n",
    "\n",
    "![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)\n",
    "![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)\n",
    "![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from args import rawdata_path, workdata_path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract target stock from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2330 台積電</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>202.703201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2330 台積電</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>199.009293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2330 台積電</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>192.083206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2330 台積電</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>196.700607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2330 台積電</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>194.853607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code       Date       Price\n",
       "0  2330 台積電 2019-01-02  202.703201\n",
       "1  2330 台積電 2019-01-03  199.009293\n",
       "2  2330 台積電 2019-01-04  192.083206\n",
       "3  2330 台積電 2019-01-07  196.700607\n",
       "4  2330 台積電 2019-01-08  194.853607"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from args import stock_code\n",
    "from etl_func.etl_data import extract_stock_df\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "stock_df = extract_stock_df(stock_code)\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "stock_df.to_parquet(stock_code + '_stock_df.parquet', index=False)\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cut Article Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish bbs with 5482 words.\n",
      "Finish news2019 with 4621 words.\n",
      "Finish news2020 with 3307 words.\n",
      "Finish news2021 with 4214 words.\n",
      "Finish forum2019 with 2778 words.\n",
      "Finish forum2020 with 4438 words.\n",
      "Finish forum2021 with 6423 words.\n"
     ]
    }
   ],
   "source": [
    "from etl_func.cut_text import Cut_Machine\n",
    "from args import (\n",
    "    company, kw_list, data_time, datafile_name,\n",
    "    kw_title_num, kw_content_num\n",
    "    )\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "final_df = pd.DataFrame()\n",
    "for source in datafile_name:\n",
    "    cut_machine = Cut_Machine(\n",
    "        articles_source=datafile_name[source],\n",
    "        data_time=data_time\n",
    "        )\n",
    "    cut_machine.filter_article(\n",
    "        keywords=kw_list,\n",
    "        title_times=kw_title_num,\n",
    "        content_times=kw_content_num\n",
    "        )\n",
    "    word_df = cut_machine.Pool_sep_all_articles()\n",
    "    final_df = pd.concat([final_df, word_df], ignore_index=True)\n",
    "    print('Finish', source, 'with', word_df.shape[0], 'words.')\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "final_df.to_parquet(company + '_word_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperparameters Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_func.train import create_train_function, plot_arg_train\n",
    "import numpy as np\n",
    "from args import args_class\n",
    "os.chdir(workdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from df_func.make_XY import Words_Matrix, feature_X_byChi2\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "train_function = Callable[[list], dict]\n",
    "\n",
    "from args import args_dict, args_class\n",
    "args = args_class(args_dict)\n",
    "words_matrix = Words_Matrix(\n",
    "    word_df=args.word_df,\n",
    "    stock_df=transform_stock_df(\n",
    "        args.stock_df, D=args.day_arg, cutoff=args.cutoff_arg\n",
    "        ),\n",
    "    data_time=args.data_time,\n",
    "    stop_words=args.stop_words\n",
    "    )\n",
    "X, Y = words_matrix.X_matrix, words_matrix.Y_matrix\n",
    "print(X.shape, Y.shape)\n",
    "X = X[ feature_X_byChi2(X, Y, k=args.features_num) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_list = [0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "train_k_feature = create_train_function('cutoff_arg')\n",
    "results = train_k_feature(cut_list)\n",
    "np.save('cutoff_arg.npy', pd.DataFrame(results).reset_index())\n",
    "plot_arg_train('cutoff_arg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2, 3, 4, 5]\n",
    "train_k_feature = create_train_function('day_arg')\n",
    "results = train_k_feature(lag_list)\n",
    "np.save('day_arg.csv', pd.DataFrame(results).reset_index())\n",
    "plot_arg_train('day_arg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [500, 1000, 1500, 2000, 2500]\n",
    "train_k_feature = create_train_function('features_num')\n",
    "results = train_k_feature(k_list)\n",
    "np.save('features_num.csv', pd.DataFrame(results).reset_index())\n",
    "plot_arg_train('features_num.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train & Test 1: 過去測試未來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "from df_func.make_XY import Words_Matrix\n",
    "from df_func.predict import Predict_Machine\n",
    "from args import (\n",
    "    word_df, stock_df, stop_words,\n",
    "    day_arg, cutoff_arg, features_num\n",
    "    )\n",
    "\n",
    "train_words_matrix = Words_Matrix(\n",
    "    word_df=word_df,\n",
    "    stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "    data_time=(datetime.date(2019,1,1), datetime.date(2021,5,31)),\n",
    "    stop_words=stop_words\n",
    "    )\n",
    "\n",
    "test_words_matrix = Words_Matrix(\n",
    "    word_df=word_df,\n",
    "    stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "    data_time=(datetime.date(2021,6,1), datetime.date(2021,12,31)),\n",
    "    stop_words=stop_words\n",
    "    )\n",
    "\n",
    "RDclf = RidgeClassifier(alpha = 0.05)\n",
    "\n",
    "ridge_machine = Predict_Machine(\n",
    "    train_words_matrix=train_words_matrix,\n",
    "    test_words_matrix=test_words_matrix,\n",
    "    features_num=features_num,\n",
    "    classifier=RDclf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "           True  False\n",
      "Positive   103      1\n",
      "Negative    14      0\n",
      "\n",
      "Accuracy Score: 0.873\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:\\n', ridge_machine.show_confusion())\n",
    "print()\n",
    "print('Accuracy Score:', round(ridge_machine.show_accuracy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train & Test 2: 移動回測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Accuracy Score: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:11<05:38, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Accuracy Score: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:20<04:47, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th Accuracy Score: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:30<04:23,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th Accuracy Score: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:39<04:06,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th Accuracy Score: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:48<03:54,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th Accuracy Score: 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:58<03:48,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th Accuracy Score: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:10<03:57, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th Accuracy Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:19<03:38,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (1, 1), indices imply (2, 2)\n",
      "8th Accuracy Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:28<03:22,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (1, 1), indices imply (2, 2)\n",
      "9th Accuracy Score: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:37<03:09,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th Accuracy Score: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:45<02:54,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th Accuracy Score: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:54<02:42,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th Accuracy Score: 0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [02:02<02:29,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th Accuracy Score: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:11<02:18,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th Accuracy Score: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [02:23<02:27,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th Accuracy Score: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [02:37<02:32, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th Accuracy Score: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [02:50<02:33, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th Accuracy Score: 0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [03:03<02:22, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th Accuracy Score: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [03:18<02:22, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th Accuracy Score: 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [03:34<02:18, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th Accuracy Score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [03:52<02:15, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th Accuracy Score: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [04:10<02:06, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th Accuracy Score: 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [04:26<01:51, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th Accuracy Score: 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [04:44<01:40, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th Accuracy Score: 0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [05:01<01:23, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Accuracy Score: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [05:17<01:05, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th Accuracy Score: 0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [05:34<00:49, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th Accuracy Score: 0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [05:52<00:34, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th Accuracy Score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [06:10<00:17, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th Accuracy Score: 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:26<00:00, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix in total:\n",
      "           True  False\n",
      "Positive   756      0\n",
      "Negative   128      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "from df_func.make_XY import Words_Matrix\n",
    "from df_func.predict import Predict_Machine, Date_Machine\n",
    "from args import (\n",
    "    word_df, stock_df, stop_words,\n",
    "    day_arg, cutoff_arg, features_num,\n",
    "    data_time\n",
    "    )\n",
    "\n",
    "result_matrix = pd.DataFrame(\n",
    "            [[0, 0], [0, 0]],\n",
    "            index=['Positive', 'Negative'],\n",
    "            columns=['True', 'False'],\n",
    "            )\n",
    "date_machine = Date_Machine(train_duration=5, test_duration=2, data_time=data_time)\n",
    "\n",
    "for i in range(30):\n",
    "    date_machine.index = i\n",
    "\n",
    "    train_words_matrix = Words_Matrix(\n",
    "        word_df=word_df,\n",
    "        stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "        data_time=date_machine.train_date,\n",
    "        stop_words=stop_words\n",
    "        )\n",
    "\n",
    "    test_words_matrix = Words_Matrix(\n",
    "        word_df=word_df,\n",
    "        stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "        data_time=date_machine.test_date,\n",
    "        stop_words=stop_words\n",
    "        )\n",
    "\n",
    "    RDclf = RidgeClassifier(alpha = 0.05)\n",
    "\n",
    "    ridge_machine = Predict_Machine(\n",
    "        train_words_matrix=train_words_matrix,\n",
    "        test_words_matrix=test_words_matrix,\n",
    "        features_num=features_num,\n",
    "        classifier=RDclf\n",
    "        )\n",
    "    print(f'{i}th Accuracy Score:', round(ridge_machine.show_accuracy(), 3))\n",
    "\n",
    "    try:\n",
    "        result_matrix += ridge_machine.show_confusion()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print('Confusion Matrix in total:\\n', result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試: why knn is nan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from df_func.train import train\n",
    "from args import args_dict, args_class\n",
    "from df_func.make_XY import Words_Matrix, feature_X_byChi2\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "arg_name = 'cutoff_arg'\n",
    "all_results = {}\n",
    "for value_ in [0]:\n",
    "    args_dict[arg_name] = value_\n",
    "    args = args_class(args_dict)\n",
    "    words_matrix = Words_Matrix(\n",
    "        word_df=args.word_df,\n",
    "        stock_df=transform_stock_df(\n",
    "            args.stock_df, D=args.day_arg, cutoff=args.cutoff_arg\n",
    "            ),\n",
    "        data_time=args.data_time,\n",
    "        stop_words=args.stop_words\n",
    "        )\n",
    "    X, Y = words_matrix.X_matrix, words_matrix.Y_matrix\n",
    "    X = X[ feature_X_byChi2(X, Y, k=args.features_num) ]\n",
    "\n",
    "    print(\"資料中漲跌的比例: \\n\", Y.value_counts())\n",
    "\n",
    "    classifier_dict_={ 'kNN': KNeighborsClassifier }\n",
    "    for classifier in classifier_dict_:\n",
    "        clf = classifier_dict_[classifier]()\n",
    "        scores = cross_val_score(estimator=clf, X=X , y=Y, cv=5)\n",
    "        print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
