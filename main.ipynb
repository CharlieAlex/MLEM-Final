{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文字預測股票漲跌專案\n",
    "\n",
    "***根據網路上各類新聞文章預測某一公司股價的漲跌***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "台大經研所 羅偉駿\n",
    "\n",
    "![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)\n",
    "![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)\n",
    "![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from args import rawdata_path, workdata_path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract target stock from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2454 聯發科</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>210.470795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2454 聯發科</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>213.334305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2454 聯發科</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>207.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2454 聯發科</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>209.039001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2454 聯發科</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>211.902603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code       Date       Price\n",
       "0  2454 聯發科 2019-01-02  210.470795\n",
       "1  2454 聯發科 2019-01-03  213.334305\n",
       "2  2454 聯發科 2019-01-04  207.130005\n",
       "3  2454 聯發科 2019-01-07  209.039001\n",
       "4  2454 聯發科 2019-01-08  211.902603"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from args import stock_code\n",
    "from etl_func.etl_data import extract_stock_df\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "stock_df = extract_stock_df(stock_code)\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "stock_df.to_parquet(stock_code + '_stock_df.parquet', index=False)\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cut Article Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish:bbs\n",
      "Finish:news2019\n",
      "Finish:news2020\n",
      "Finish:news2021\n",
      "Finish:forum2019\n",
      "Finish:forum2020\n",
      "Finish:forum2021\n"
     ]
    }
   ],
   "source": [
    "from etl_func.cut_text import Cut_Machine\n",
    "from args import (\n",
    "    company, kw_list, data_time, datafile_name,\n",
    "    kw_title_num, kw_content_num\n",
    "    )\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "final_df = pd.DataFrame()\n",
    "for source in datafile_name:\n",
    "    cut_machine = Cut_Machine(\n",
    "        articles_source=datafile_name[source],\n",
    "        data_time=data_time\n",
    "        )\n",
    "    cut_machine.filter_article(\n",
    "        keywords=kw_list,\n",
    "        title_times=kw_title_num,\n",
    "        content_times=kw_content_num\n",
    "        )\n",
    "    word_df = cut_machine.Pool_sep_all_articles()\n",
    "    final_df = pd.concat([final_df, word_df], ignore_index=True)\n",
    "    print('Finish:' + source)\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "final_df.to_parquet(company + '_word_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get X, Y for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import day_arg, cutoff_arg, features_num\n",
    "from df_func.make_XY import Words_Matrix, feature_X_byChi2\n",
    "from etl_func.etl_data import transform_stock_df, read_stop_words\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "stop_words = read_stop_words()\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "word_df = pd.read_parquet(company + '_word_df.parquet')\n",
    "stock_df = pd.read_parquet(stock_code + '_stock_df.parquet')\n",
    "stock_df = transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg)\n",
    "\n",
    "words_matrix = Words_Matrix(word_df, stock_df, data_time, stop_words)\n",
    "X, Y = words_matrix.X_matrix, words_matrix.Y_matrix\n",
    "X = X[ feature_X_byChi2(X, Y, k=features_num) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Try training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN : nan\n",
      "[nan nan nan nan nan]\n",
      "Ridge : 0.893\n",
      "[0.89230769 0.89128205 0.89538462 0.89527721 0.89219713]\n",
      "Desision Tree : 0.867\n",
      "[0.88512821 0.85333333 0.8625641  0.87782341 0.85626283]\n",
      "Random Forest : 0.894\n",
      "[0.89948718 0.88820513 0.89333333 0.89219713 0.8963039 ]\n",
      "Gradient Boosting : 0.892\n",
      "[0.89538462 0.88512821 0.89230769 0.89219713 0.89322382]\n",
      "MLP : 0.895\n",
      "[0.90153846 0.89025641 0.89333333 0.90349076 0.88501027]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from args import classifier_dict\n",
    "\n",
    "for classifier in classifier_dict:\n",
    "    clf = classifier_dict[classifier]()\n",
    "    scores = cross_val_score(clf, X , Y, cv = 5)\n",
    "    print(classifier, ':', round(scores.mean(), 3))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameters Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_func.train import create_train_function\n",
    "os.chdir(workdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_list = [0, 0.01, 0.02, 0.03, 0.04]\n",
    "train_k_feature = create_train_function('cutoff_arg')\n",
    "results = train_k_feature(cut_list)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('cutoff_arg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2, 3, 4, 5]\n",
    "train_k_feature = create_train_function('day_arg')\n",
    "results = train_k_feature(lag_list)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('day_arg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [500, 1000, 1500, 2000, 2500]\n",
    "train_k_feature = create_train_function('features_num')\n",
    "results = train_k_feature(k_list)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('features_num.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train & Test 1: 過去測試未來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "from df_func.make_XY import Words_Matrix\n",
    "from df_func.predict import Predict_Machine\n",
    "from args import (\n",
    "    word_df, stock_df, stop_words,\n",
    "    day_arg, cutoff_arg, features_num\n",
    "    )\n",
    "\n",
    "train_words_matrix = Words_Matrix(\n",
    "    word_df=word_df,\n",
    "    stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "    data_time=(datetime.date(2019,1,1), datetime.date(2021,5,31)),\n",
    "    stop_words=stop_words\n",
    "    )\n",
    "\n",
    "test_words_matrix = Words_Matrix(\n",
    "    word_df=word_df,\n",
    "    stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "    data_time=(datetime.date(2021,6,1), datetime.date(2021,12,31)),\n",
    "    stop_words=stop_words\n",
    "    )\n",
    "\n",
    "RDclf = RidgeClassifier(alpha = 0.05)\n",
    "\n",
    "ridge_machine = Predict_Machine(\n",
    "    train_words_matrix=train_words_matrix,\n",
    "    test_words_matrix=test_words_matrix,\n",
    "    features_num=features_num,\n",
    "    classifier=RDclf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "           True  False\n",
      "Positive   103      1\n",
      "Negative    14      0\n",
      "\n",
      "Accuracy Score: 0.873\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:\\n', ridge_machine.show_confusion())\n",
    "print()\n",
    "print('Accuracy Score:', round(ridge_machine.show_accuracy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train & Test 2: 移動回測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Accuracy Score: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:11<05:38, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Accuracy Score: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:20<04:47, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th Accuracy Score: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:30<04:23,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th Accuracy Score: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:39<04:06,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th Accuracy Score: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:48<03:54,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th Accuracy Score: 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:58<03:48,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th Accuracy Score: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:10<03:57, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th Accuracy Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:19<03:38,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (1, 1), indices imply (2, 2)\n",
      "8th Accuracy Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:28<03:22,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (1, 1), indices imply (2, 2)\n",
      "9th Accuracy Score: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:37<03:09,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th Accuracy Score: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:45<02:54,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th Accuracy Score: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:54<02:42,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th Accuracy Score: 0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [02:02<02:29,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th Accuracy Score: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:11<02:18,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th Accuracy Score: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [02:23<02:27,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th Accuracy Score: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [02:37<02:32, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th Accuracy Score: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [02:50<02:33, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th Accuracy Score: 0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [03:03<02:22, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th Accuracy Score: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [03:18<02:22, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th Accuracy Score: 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [03:34<02:18, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th Accuracy Score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [03:52<02:15, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th Accuracy Score: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [04:10<02:06, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th Accuracy Score: 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [04:26<01:51, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th Accuracy Score: 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [04:44<01:40, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th Accuracy Score: 0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [05:01<01:23, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Accuracy Score: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [05:17<01:05, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th Accuracy Score: 0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [05:34<00:49, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th Accuracy Score: 0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [05:52<00:34, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th Accuracy Score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [06:10<00:17, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th Accuracy Score: 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:26<00:00, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix in total:\n",
      "           True  False\n",
      "Positive   756      0\n",
      "Negative   128      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from etl_func.etl_data import transform_stock_df\n",
    "from df_func.make_XY import Words_Matrix\n",
    "from df_func.predict import Predict_Machine, Date_Machine\n",
    "from args import (\n",
    "    word_df, stock_df, stop_words,\n",
    "    day_arg, cutoff_arg, features_num,\n",
    "    data_time\n",
    "    )\n",
    "\n",
    "result_matrix = pd.DataFrame(\n",
    "            [[0, 0], [0, 0]],\n",
    "            index=['Positive', 'Negative'],\n",
    "            columns=['True', 'False'],\n",
    "            )\n",
    "date_machine = Date_Machine(train_duration=5, test_duration=2, data_time=data_time)\n",
    "\n",
    "for i in range(30):\n",
    "    date_machine.index = i\n",
    "\n",
    "    train_words_matrix = Words_Matrix(\n",
    "        word_df=word_df,\n",
    "        stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "        data_time=date_machine.train_date,\n",
    "        stop_words=stop_words\n",
    "        )\n",
    "\n",
    "    test_words_matrix = Words_Matrix(\n",
    "        word_df=word_df,\n",
    "        stock_df=transform_stock_df(stock_df, D=day_arg, cutoff=cutoff_arg),\n",
    "        data_time=date_machine.test_date,\n",
    "        stop_words=stop_words\n",
    "        )\n",
    "\n",
    "    RDclf = RidgeClassifier(alpha = 0.05)\n",
    "\n",
    "    ridge_machine = Predict_Machine(\n",
    "        train_words_matrix=train_words_matrix,\n",
    "        test_words_matrix=test_words_matrix,\n",
    "        features_num=features_num,\n",
    "        classifier=RDclf\n",
    "        )\n",
    "    print(f'{i}th Accuracy Score:', round(ridge_machine.show_accuracy(), 3))\n",
    "\n",
    "    try:\n",
    "        result_matrix += ridge_machine.show_confusion()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print('Confusion Matrix in total:\\n', result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
