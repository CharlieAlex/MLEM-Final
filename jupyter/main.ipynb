{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料處理\n",
    "import numpy as np                     #資料處理2陣列\n",
    "import pandas as pd                    #資料處理1資料框\n",
    "from math import nan\n",
    "\n",
    "#統計\n",
    "import random                          #指定隨機狀態1\n",
    "random.seed(123)                       #指定隨機狀態2\n",
    "\n",
    "#時間\n",
    "import datetime\n",
    "\n",
    "#其他\n",
    "from tqdm import tqdm, trange          #用來掌管 for 進度\n",
    "import os                              #用來控制路徑\n",
    "import warnings                        #用來消除警告\n",
    "warnings.filterwarnings(\"ignore\")      #用來消除警告設定\n",
    "\n",
    "#文字處理\n",
    "import monpa\n",
    "from monpa import utils\n",
    "import re\n",
    "\n",
    "# 平行化\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import  Pool as ThreadPool\n",
    "\n",
    "# Path\n",
    "rawdata_path = '/Users/alexlo/Desktop/Project/Project_MLEM/rawdata'\n",
    "workdata_path = '/Users/alexlo/Desktop/Project/Project_MLEM/workdata'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl_func.stock_data import get_StockDF\n",
    "\n",
    "os.chdir(rawdata_path)\n",
    "stock_df = get_StockDF('2303')\n",
    "\n",
    "os.chdir(workdata_path)\n",
    "stock_df.to_parquet('聯電.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Article "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonChinese(sentence):\n",
    "    return re.sub(r'[^\\u4e00-\\u9fa5]+', '', sentence)\n",
    "\n",
    "def shorten_word(word_list: list) -> list:\n",
    "    for word in word_list:\n",
    "        if word.startswith(('一', '二','三','四','五','六','七','八','九','十')):\n",
    "            word_list.remove(word)\n",
    "            continue\n",
    "        if len(word) >= 5:\n",
    "            word_list.remove(word)\n",
    "            word_list.append(word[:2])\n",
    "            word_list.append(word[2:])\n",
    "    return word_list\n",
    "    \n",
    "def combine_np_files(stock_code):\n",
    "    '''\n",
    "    Combine all the np files startwith 'stock_code'\n",
    "    '''\n",
    "    os.chdir(workdata_path)\n",
    "    file_list = [file for file in os.listdir() if file.startswith(stock_code)]\n",
    "    words_array = np.array([])\n",
    "    for file in file_list:\n",
    "        words_array = np.append(words_array, np.load(file))\n",
    "        words_array = np.array(words_array)\n",
    "        os.remove(file)\n",
    "        np.save(stock_code + '_words', words_array)\n",
    "    return words_array\n",
    "\n",
    "def drop_bda2022(stock_code):\n",
    "    '''\n",
    "    os 刪除所有bda2022開頭的檔案，測試使用\n",
    "    '''\n",
    "    os.chdir(workdata_path)\n",
    "    for file in os.listdir():\n",
    "        if file.startswith(stock_code):\n",
    "            os.remove(file)\n",
    "\n",
    "class Words_Dataset:\n",
    "    def __init__(self, data_source, stock_code, start_date, end_date):\n",
    "        os.chdir(rawdata_path)\n",
    "        self.data_source = data_source\n",
    "        self.stock_code = stock_code\n",
    "        self.article_df = pd.read_csv(data_source)\n",
    "        self.start_date = start_date \n",
    "        self.end_date = end_date\n",
    "        \n",
    "    def select_article(self, keywords, title_times, content_times):\n",
    "        self.article_df['post_time'] = pd.to_datetime(self.article_df['post_time']).dt.date\n",
    "        self.article_df = self.article_df[(self.article_df['title'].str.count('|'.join(keywords)) >= title_times) |\n",
    "                                (self.article_df['content'].str.count('|'.join(keywords)) >= content_times)]. \\\n",
    "                                reset_index(drop = True)\n",
    "        return self.article_df\n",
    "        \n",
    "    def get_indexlist_for_multi(self):\n",
    "        num_rows = self.article_df.shape[0]\n",
    "        start_index_list = [i*50 for i in range(int(num_rows / 50)+1)] \n",
    "        end_index_list = [(i+1)*50 for i in range(int(num_rows / 50))]\n",
    "        end_index_list.append(num_rows)\n",
    "        index_list = [ [start_index_list[i], end_index_list[i]] for i in range(len(start_index_list)) ]\n",
    "        return index_list\n",
    "\n",
    "    def get_words_matrix(self, index):\n",
    "        print('Running:', index)\n",
    "        df = self.article_df.iloc[index[0]:index[1]].reset_index(drop=True)\n",
    "        article_into_words_list = []\n",
    "        len_of_df = df.shape[0]\n",
    "        error_times = 0\n",
    "        for i in range(0, len_of_df): #幾篇文章就要跑幾次\n",
    "            article_into_words = str()\n",
    "            try:    \n",
    "                article = df['content'][i]\n",
    "                sentence_list = utils.short_sentence(article) #先把一篇文章切成很多句\n",
    "                for sentence in sentence_list: #再針對每一句切成很多個字\n",
    "                    sentence = remove_nonChinese(sentence)\n",
    "                    word_list = monpa.cut_batch(sentence)\n",
    "                    word_list = word_list[0] #為了batch\n",
    "                    if word_list is not None:\n",
    "                        word_list = shorten_word(word_list)\n",
    "                        article_into_words += ' '.join(word_list)\n",
    "                article_into_words_list.append(article_into_words)\n",
    "            except:\n",
    "                error_times += 1\n",
    "                article_into_words_list.append('')\n",
    "        if error_times > 0:\n",
    "            print(f'Error Times in {index}:', error_times)\n",
    "        # Save\n",
    "        os.chdir(workdata_path)\n",
    "        words_array = np.array(article_into_words_list)\n",
    "        save_name = stock_code + '_' + (self.data_source.split('_')[2] + self.data_source.split('_')[3])[:-4] + '_words_' + str(index[0])\n",
    "        np.save(save_name, words_array)\n",
    "        return error_times\n",
    "    \n",
    "    def get_words_matrix_multi(self, index_list):\n",
    "        pool = ThreadPool(8)\n",
    "        error_times = pool.map(self.get_words_matrix, index_list)\n",
    "        pool.close()\n",
    "        pool.join()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.date(2019,1,1) \n",
    "end_date = datetime.date(2021,1,1) \n",
    "data_time = (start_date, end_date)\n",
    "a, b = data_time\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article source\n",
    "bbs = 'bda2022_mid_bbs_2019-2021.csv'\n",
    "forum2019 = 'bda2022_mid_forum_2019.csv' \n",
    "forum2020 = 'bda2022_mid_forum_2020.csv'\n",
    "forum2021 = 'bda2022_mid_forum_2021.csv'\n",
    "news2019 = 'bda2022_mid_news_2019.csv'\n",
    "news2020 = 'bda2022_mid_news_2020.csv'\n",
    "news2021 = 'bda2022_mid_news_2021.csv'\n",
    "\n",
    "# parameters\n",
    "start_date = datetime.date(2019,1,1) \n",
    "end_date = datetime.date(2021,1,1) \n",
    "stock_code = '2303'\n",
    "keywords = ['聯電'] #公司名字（各種可能名字）、產業名字\n",
    "title_times = 1\n",
    "content_times = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Source: bda2022_mid_forum_2019.csv\n",
      "There are  165 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 165]\n",
      "Error Times in [50, 100]: 1\n",
      "Error Times in [100, 150]: 2\n",
      "Error Times in [0, 50]: 3\n",
      "Finished: bda2022_mid_forum_2019.csv\n",
      "Data Source: bda2022_mid_forum_2020.csv\n",
      "There are  361 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 361]\n",
      "Error Times in [300, 350]: 1\n",
      "Error Times in [0, 50]: 3\n",
      "Error Times in [200, 250]: 2\n",
      "Finished: bda2022_mid_forum_2020.csv\n",
      "Data Source: bda2022_mid_forum_2021.csv\n",
      "There are  600 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 400]\n",
      "Running: [400, 450]\n",
      "Running: [450, 500]\n",
      "Error Times in [400, 450]: 1\n",
      "Running: [500, 550]\n",
      "Error Times in [0, 50]: 1\n",
      "Running: [550, 600]\n",
      "Running: [600, 600]\n",
      "Error Times in [50, 100]: 2\n",
      "Error Times in [450, 500]: 4\n",
      "Error Times in [200, 250]: 1\n",
      "Finished: bda2022_mid_forum_2021.csv\n",
      "Data Source: bda2022_mid_news_2019.csv\n",
      "There are  914 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 400]\n",
      "Running: [400, 450]\n",
      "Running: [450, 500]\n",
      "Running: [500, 550]\n",
      "Running: [550, 600]\n",
      "Running: [600, 650]\n",
      "Running: [650, 700]\n",
      "Running: [700, 750]\n",
      "Running: [750, 800]\n",
      "Running: [800, 850]\n",
      "Running: [850, 900]\n",
      "Running: [900, 914]\n",
      "Finished: bda2022_mid_news_2019.csv\n",
      "Data Source: bda2022_mid_news_2020.csv\n",
      "There are  974 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 400]\n",
      "Running: [400, 450]\n",
      "Running: [450, 500]\n",
      "Running: [500, 550]\n",
      "Running: [550, 600]\n",
      "Running: [600, 650]\n",
      "Running: [650, 700]\n",
      "Running: [700, 750]\n",
      "Running: [750, 800]\n",
      "Running: [800, 850]\n",
      "Running: [850, 900]\n",
      "Running: [900, 950]\n",
      "Running: [950, 974]\n",
      "Finished: bda2022_mid_news_2020.csv\n",
      "Data Source: bda2022_mid_news_2021.csv\n",
      "There are  1,415 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 400]\n",
      "Running: [400, 450]\n",
      "Running: [450, 500]\n",
      "Running: [500, 550]\n",
      "Running: [550, 600]\n",
      "Running: [600, 650]\n",
      "Running: [650, 700]\n",
      "Running: [700, 750]\n",
      "Running: [750, 800]\n",
      "Running: [800, 850]\n",
      "Running: [850, 900]\n",
      "Running: [900, 950]\n",
      "Running: [950, 1000]\n",
      "Running: [1000, 1050]\n",
      "Running: [1050, 1100]\n",
      "Running: [1100, 1150]\n",
      "Running: [1150, 1200]\n",
      "Running: [1200, 1250]\n",
      "Running: [1250, 1300]\n",
      "Running: [1300, 1350]\n",
      "Running: [1350, 1400]\n",
      "Running: [1400, 1415]\n",
      "Finished: bda2022_mid_news_2021.csv\n",
      "Data Source: bda2022_mid_bbs_2019-2021.csv\n",
      "There are  801 artilces after selecting.\n",
      "Running: [0, 50]\n",
      "Running: [50, 100]\n",
      "Running: [100, 150]\n",
      "Running: [150, 200]\n",
      "Running: [200, 250]\n",
      "Running: [250, 300]\n",
      "Running: [300, 350]\n",
      "Running: [350, 400]\n",
      "Running: [400, 450]\n",
      "Running: [450, 500]\n",
      "Running: [500, 550]\n",
      "Running: [550, 600]\n",
      "Running: [600, 650]\n",
      "Running: [650, 700]\n",
      "Running: [700, 750]\n",
      "Running: [750, 800]\n",
      "Running: [800, 801]\n",
      "Finished: bda2022_mid_bbs_2019-2021.csv\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "for data_source in [forum2019, forum2020, forum2021, news2019, news2020, news2021, bbs]:\n",
    "    print(f\"Data Source: {data_source}\")\n",
    "    words_dataset = Words_Dataset(data_source, stock_code, start_date, end_date)\n",
    "    article_df = words_dataset.select_article(keywords, title_times, content_times)\n",
    "    print(f\"There are {article_df.shape[0]: ,} artilces after selecting.\")\n",
    "    index_list = words_dataset.get_indexlist_for_multi()\n",
    "    words_dataset.get_words_matrix_multi(index_list)\n",
    "    print(f\"Finished: {data_source}\")\n",
    "\n",
    "words_array = combine_np_files('2303')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Stock & Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5230 articles in total.\n"
     ]
    }
   ],
   "source": [
    "### 設定的參數（有需要的話，可以直接修改成股票代碼以及股票檔案）\n",
    "code = stock_code\n",
    "keywords = ['聯電'] #the keyword to filter the articles\n",
    "keywords_times_titles = 1\n",
    "keywords_times_content = 2\n",
    "\n",
    "\n",
    "### 讀取文章資料\n",
    "os.chdir(rawdata_path)\n",
    "article_df = pd.read_csv('bda2022_mid_bbs_2019-2021.csv')\n",
    "article_df = article_df.rename(columns={'post_time':'Post_Time', 'title':'Title', 'content':'Content'})\n",
    "article_df['Post_Time'] = pd.to_datetime(article_df['Post_Time']).dt.date\n",
    "criteria1 = (article_df['Title'].str.count('|'.join(keywords)) >= keywords_times_titles)\n",
    "criteria2 = (article_df['Content'].str.count('|'.join(keywords)) >= keywords_times_content)\n",
    "article_df = article_df[(criteria1) | (criteria2)].reset_index(drop = True)\n",
    "\n",
    "### 讀取文字資料\n",
    "os.chdir(workdata_path)\n",
    "all_words = np.load(code + '_words.npy').tolist()\n",
    "print(\"There are\", len(all_words), \"articles in total.\")\n",
    "\n",
    "### 讀取股價資料\n",
    "stock_df = pd.read_parquet('聯電.parquet').astype({'Date':'datetime64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['很多 公司 都 是 這樣 搞 的 啊 美其名 激勵 員工 但 其實 分配 到 底層 員工 能 認 個 張 就算 多 的 了 絕 大多數 都 是 高層 分配 走 了',\n",
       " '這 很 正常 啊 他 是 分批 買進 最 低 有 多元 買 所以 平均 大約 元 左右 這 個 時候 開放 員工 認購 正好 可以 激勵 員工 員工 也 不 是 無償 取得 之後 依 員工 職級 與 年資 來 計算 可 認購 張數 很多 公司 都 是 這樣 做',\n",
       " '股東 不能 認 股 真的 跟 大同 沒 兩樣 股東 喝 西北風 你們 這些 出錢 的 最 小 拿到 經營權 再 跟 公司 說',\n",
       " '站 在 非 股東 立場 來 看 為何 不 是 全體 含 基層 員工 認購 呢 只 有 主管 階層 能 套利 果然 基層 該 死 吃相 更 難 看']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_df\n",
    "all_words[1:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
